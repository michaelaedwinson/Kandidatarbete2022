{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b76ce5a-e71a-4787-8d01-c9e7d08c0bcd",
   "metadata": {},
   "source": [
    "# This notebook is to adjust and save files that are worked with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cc2fc-69fa-44db-9d30-85a54aabfaa7",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7a2068-257d-4d40-a87f-cd302980463c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os \n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import gsw\n",
    "import cmocean as cmo\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset as nc\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "font = {'weight' : 'normal',\n",
    "        'size'  : 20}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad218d05-1957-4a6c-9b98-0620cfb83dd0",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67100c73-ecc6-4aef-bd5e-c0b89ec1e204",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def wind_sp_kt_to_ms(wind_kts):\n",
    "    \n",
    "    return wind_kts*0.514444  #kt to m/s\n",
    "\n",
    "def wind_sp_to_10m(wind_sp, z0=1.52e-4, zm=3.4, z10=10):\n",
    "    \n",
    "    \"\"\"Correct wind speed data from a given height to 10m above sea level.\n",
    "\n",
    "       wind_sp = wind speed measurement (m/s)\n",
    "       z0      = roughness length\n",
    "       zm      = height of wind measurement\n",
    "       z10     = height to correct to\n",
    "    \"\"\"\n",
    "    \n",
    "    return wind_sp*(math.log(z10/z0)/math.log(zm/z0))\n",
    "\n",
    "def wind_direction(v, u):\n",
    "    DIR=90-np.rad2deg(np.arctan(v / u) )\n",
    "    return DIR\n",
    "\n",
    "from tqdm import tqdm  # Assuming you're using the tqdm library for progress tracking\n",
    "\n",
    "def colocate_era5_sd(sd, era5, var):\n",
    "    \"\"\"\n",
    "    Colocates ERA5 data with Shipboard Data (SD) based on time, latitude, and longitude.\n",
    "\n",
    "    Args:\n",
    "    - sd (xarray.Dataset): Shipboard Data with time, longitude, and latitude dimensions.\n",
    "    - era5 (xarray.Dataset): ERA5 data with time, longitude, and latitude dimensions.\n",
    "    - var (str): The variable to be colocated.\n",
    "\n",
    "    Returns:\n",
    "    - era5_var (numpy.ndarray): An array of ERA5 variable values colocated with SD.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty array to store ERA5 variable values\n",
    "    era5_var = np.ndarray(sd.time.size)\n",
    "\n",
    "    # Iterate through each time step in Shipboard Data (SD)\n",
    "    for t in tqdm(range(sd.time.size)):\n",
    "\n",
    "        # Find the matching time index in ERA5 data\n",
    "        idx = sd.time[t] == era5.time\n",
    "\n",
    "        # Find the latitude and longitude indices in ERA5 data that are closest to SD coordinates\n",
    "        lon_idx = np.argmin(np.abs(sd.longitude.data[t] - era5.longitude.data))\n",
    "        lat_idx = np.argmin(np.abs(sd.latitude.data[t] - era5.latitude.data))\n",
    "\n",
    "        # Extract and store the ERA5 variable value for the matching time and location\n",
    "        era5_var[t] = era5.isel(time=idx, latitude=lat_idx, longitude=lon_idx)[var].data\n",
    "\n",
    "    return era5_var\n",
    "\n",
    "def era5dewtorh(era5_ds):\n",
    "    # Extract dew point temperature (Dp) values from the input dataset\n",
    "    Dp = era5_ds.d2m.values-273.15 # dew point temperature in celsius\n",
    "\n",
    "    # Extract air temperature (T) values from the input dataset, and convert to celsius\n",
    "    T = era5_ds.t2m.values # temperature in celsius\n",
    "    \n",
    "    # Calculate relative humidity (RH) using the formula and add it to the input dataset\n",
    "    era5_ds['rh'] = (('time', 'latitude', 'longitude'),\n",
    "                     100 * (np.exp((17.625 * Dp) / (243.04 + Dp)) / np.exp((17.625 * T) / (243.04 + T))))\n",
    "    \n",
    "    # Return the input dataset with the 'rh' variable added\n",
    "    return era5_ds\n",
    "\n",
    "def dist_era5_sd(sd, era5):\n",
    "    \"\"\"\n",
    "    Colocates ERA5 data with Shipboard Data (SD) based on time, latitude, and longitude.\n",
    "\n",
    "    Args:\n",
    "    - sd (xarray.Dataset): Shipboard Data with time, longitude, and latitude dimensions.\n",
    "    - era5 (xarray.Dataset): ERA5 data with time, longitude, and latitude dimensions.\n",
    "\n",
    "    Returns:\n",
    "    - dist (numpy.ndarray): An array of distance in meters between nearest ERA5 gridpoint and SD.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty array to store ERA5 variable values\n",
    "    dist = np.ndarray(sd.time.size)\n",
    "    #time = np.ndarray(sd.time.size)\n",
    "    # Iterate through each time step in Shipboard Data (SD)\n",
    "    for t in tqdm(range(sd.time.size)):\n",
    "\n",
    "        # Find the matching time index in ERA5 data\n",
    "        idx = sd.time[t] == era5.time\n",
    "\n",
    "        # Find the latitude and longitude indices in ERA5 data that are closest to SD coordinates\n",
    "        lon_idx = np.argmin(np.abs(sd.longitude.data[t] - era5.longitude.data))\n",
    "        lat_idx = np.argmin(np.abs(sd.latitude.data[t] - era5.latitude.data))\n",
    "\n",
    "        # Extract and store the ERA5 variable value for the matching time and location\n",
    "        dist[t] = gsw.distance([era5.isel(time=idx, latitude=lat_idx, longitude=lon_idx)['longitude'].data, sd.longitude[t]],[era5.isel(time=idx, latitude=lat_idx, longitude=lon_idx)['latitude'].data, sd.latitude[t]]) \n",
    "        \n",
    "        #dist[t]= (((era5.latitude[lat_idx]-sd.latitude[lat_idx])**2)+((era5.longitude[lon_idx]-sd.longitude[lon_idx])**2))**0.5\n",
    "        #time[t] = era5.isel(time=idx, latitude=lat_idx, longitude=lon_idx)['time']\n",
    "        \n",
    "        \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9054bf-39aa-4e74-b74c-f228ff072f27",
   "metadata": {},
   "source": [
    "SD variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0a245d-cf70-4637-8fd2-1bbaeb0c968e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat = ['WIND_FROM_MEAN',\n",
    "           'WIND_FROM_STDDEV', \n",
    "           'WIND_SPEED_MEAN',\n",
    "           'WIND_SPEED_STDDEV',\n",
    "           'UWND_MEAN',\n",
    "           'UWND_STDDEV',\n",
    "           'VWND_MEAN',\n",
    "           'VWND_STDDEV',\n",
    "           'WWND_MEAN',\n",
    "           'WWND_STDDEV',\n",
    "           'GUST_WND_MEAN',\n",
    "           'GUST_WND_STDDEV',\n",
    "           'WIND_MEASUREMENT_HEIGHT_MEAN',\n",
    "           'WIND_MEASUREMENT_HEIGHT_STDDEV',\n",
    "           'TEMP_AIR_MEAN',\n",
    "           'TEMP_AIR_STDDEV',\n",
    "           'RH_MEAN',\n",
    "           'RH_STDDEV',\n",
    "           'BARO_PRES_MEAN',\n",
    "           'BARO_PRES_STDDEV',\n",
    "           'PAR_AIR_MEAN',\n",
    "           'PAR_AIR_STDDEV',\n",
    "           'LW_IRRAD_MEAN',\n",
    "           'LW_IRRAD_STDDEV',\n",
    "           'SW_IRRAD_TOTAL_MEAN',\n",
    "           'SW_IRRAD_TOTAL_STDDEV',\n",
    "           'SW_IRRAD_DIFFUSE_MEAN',\n",
    "           'SW_IRRAD_DIFFUSE_STDDEV',\n",
    "           'TEMP_IR_SEA_WING_UNCOMP_MEAN',\n",
    "           'TEMP_IR_SEA_WING_UNCOMP_STDDEV',\n",
    "           'WAVE_DOMINANT_PERIOD',\n",
    "           'WAVE_SIGNIFICANT_HEIGHT',\n",
    "           'TEMP_DEPTH_HALFMETER_MEAN',\n",
    "           'TEMP_DEPTH_HALFMETER_STDDEV',\n",
    "           'TEMP_SBE37_MEAN',\n",
    "           'TEMP_SBE37_STDDEV',\n",
    "           'SAL_SBE37_MEAN',\n",
    "           'SAL_SBE37_STDDEV',\n",
    "           'COND_SBE37_MEAN',\n",
    "           'COND_SBE37_STDDEV',\n",
    "           'O2_CONC_SBE37_MEAN',\n",
    "           'O2_CONC_SBE37_STDDEV',\n",
    "           'O2_SAT_SBE37_MEAN',\n",
    "           'O2_SAT_SBE37_STDDEV',\n",
    "           'CHLOR_WETLABS_MEAN',\n",
    "           'CHLOR_WETLABS_STDDEV',\n",
    "           'XCO2_DRY_SW_MEAN_ASVCO2',\n",
    "           'XCO2_DRY_AIR_MEAN_ASVCO2'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001e024-6fba-4750-a5bc-34d9256d9034",
   "metadata": {},
   "source": [
    "## Paths to files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a157c54f-1508-42e6-958e-4cc250e429ef",
   "metadata": {},
   "source": [
    "SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2739b897-37b7-4fe4-a5a6-c6cb723692ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = pathlib.Path('.').absolute() #absolute path to working directory\n",
    "pdir = p.parent / 'share/MISSIONS/sochic/saildrone/sd-1067/daily_files/1min/' #add p.parent and the path\n",
    "#list(pdir.glob('*.nc'))  # lista filel som slutar på .nc i filkatalogen\n",
    "\n",
    "filename=[]\n",
    "for file_path in list(pdir.glob('*.nc')): # lista filer som slutar på .nc i filkatalogen\n",
    "    filename.append(file_path.name)\n",
    "    #print(file_path.name)\n",
    "#    print(file_path.stem)\n",
    "#.   print(file_path)\n",
    "filename.sort()\n",
    "\n",
    "files=[]\n",
    "#path = pdir / filename[0]\n",
    "for i in range(len(filename)):\n",
    "    path= pdir / filename[i]\n",
    "    files.append(xr.open_dataset(path, engine='netcdf4').sel(trajectory=1067).swap_dims({'obs':'time'})[dat])\n",
    "   # files.append(xr.open_dataset(pdir / filename[i],engine='netcdf4').sel(trajectory=1067).swap_dims({'obs':'time'})[dat]) \n",
    "   # ds = xr.concat(tmp,dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a9d90-ac74-4430-90af-94f2dd9c5b57",
   "metadata": {},
   "source": [
    "ADCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292d815f-3ac3-4ddf-b1cc-6518aa74c08e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2 = pathlib.Path('.').absolute() #absolute path to working directory\n",
    "pdir2 = p2.parent / 'share/MISSIONS/sochic/saildrone/sd-1067/daily_files/adcp/' #add p.parent and the path\n",
    "#list(pdir.glob('*.nc'))  # lista filel som slutar på .nc i filkatalogen\n",
    "\n",
    "filename2=[]\n",
    "for file_path2 in list(pdir2.glob('*.nc')): # lista filer som slutar på .nc i filkatalogen\n",
    "    filename2.append(file_path2.name)\n",
    "    #print(file_path.name)\n",
    "#    print(file_path.stem)\n",
    "#.   print(file_path)\n",
    "filename2.sort()\n",
    "\n",
    "files2=[]\n",
    "#path = pdir / filename[0]\n",
    "for i in range(len(filename2)):\n",
    "    path2= pdir2 / filename2[i]\n",
    "    files2.append(xr.open_dataset(path2, engine='netcdf4').sel(trajectory=1067).swap_dims({'obs':'time'}))\n",
    "   # files.append(xr.open_dataset(pdir / filename[i],engine='netcdf4').sel(trajectory=1067).swap_dims({'obs':'time'})[dat]) \n",
    "   # ds = xr.concat(tmp,dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a586bbc-aef3-47ec-a68a-996abd02b1e8",
   "metadata": {},
   "source": [
    "OSTIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd52ed4a-c498-41e0-a8c9-63195a840d5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p3 = pathlib.Path('.').absolute() #absolute path to working directory\n",
    "pdir3 = p3.parent/'MTmichaela/MasterH23/OSTIA/' #add p.parent and the path\n",
    "#list(pdir.glob('*.nc'))  # lista filel som slutar på .nc i filkatalogen\n",
    "\n",
    "filename=[]\n",
    "for file_path in list(pdir3.glob('*.nc')): # lista filer som slutar på .nc i filkatalogen\n",
    "    filename.append(file_path.name)\n",
    "\n",
    "filename.sort()\n",
    "\n",
    "files3=[]\n",
    "#path = pdir / filename[0]\n",
    "for i in range(len(filename)):\n",
    "    path= pdir3 / filename[i]\n",
    "    files3.append(xr.open_dataset(path, engine='netcdf4'))#.sel(trajectory=1067).swap_dims({'obs':'time'})[dat])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742de8fc-cfad-48a3-bd94-027f8b96515a",
   "metadata": {},
   "source": [
    "Create and save ds & ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5daf49fd-2009-4926-8e62-4c329e364497",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = xr.concat(files,dim='time') #Gör om till ett xarray dataset'\n",
    "wind10=[]\n",
    "windu10=[]\n",
    "windv10=[]\n",
    "for i in np.arange(len(ds.WIND_MEASUREMENT_HEIGHT_MEAN)):\n",
    "    wind10.append(wind_sp_to_10m(ds.WIND_SPEED_MEAN[i], z0=1.52e-4, zm=ds.WIND_MEASUREMENT_HEIGHT_MEAN[i], z10=10))#Refer windmeasurement from SD measured height to 10 m\n",
    "    windu10.append(wind_sp_to_10m(ds.UWND_MEAN[i], z0=1.52e-4, zm=ds.WIND_MEASUREMENT_HEIGHT_MEAN[i], z10=10))\n",
    "    windv10.append(wind_sp_to_10m(ds.VWND_MEAN[i], z0=1.52e-4, zm=ds.WIND_MEASUREMENT_HEIGHT_MEAN[i], z10=10))\n",
    "    \n",
    "    #    wind2.append(wind_sp_to_10m(ds.WIND_SPEED_MEAN[i], z0=1.52e-4, zm=ds.WIND_MEASUREMENT_HEIGHT_MEAN[i], z10=2))\n",
    "ds['WIND_CORR10']=xr.concat(wind10, dim='time')\n",
    "ds['u10']=xr.concat(windu10, dim='time')\n",
    "ds['v10']=xr.concat(windv10, dim='time')\n",
    "ds['SAL_ABS']=(gsw.SA_from_SP(ds.SAL_SBE37_MEAN,0, ds.longitude, ds.latitude) )\n",
    "ds['TEMP_CONS']=gsw.CT_from_t(ds.SAL_ABS, ds.TEMP_SBE37_MEAN,0)\n",
    "ds['DENS']=gsw.rho(ds.SAL_ABS, ds.TEMP_CONS, 0)\n",
    "#ds['WIND_CORR2']=xr.concat(wind2, dim='time')\n",
    "\n",
    "\n",
    "ds=ds.rename({'BARO_PRES_MEAN':'P_SEA'})\n",
    "ds=ds.rename({'LW_IRRAD_MEAN':'dwlw'})\n",
    "ds=ds.rename({'SW_IRRAD_TOTAL_MEAN':'dwsw'})\n",
    "ds=ds.rename({'TEMP_SBE37_MEAN':'sst'})\n",
    "ds=ds.rename({'TEMP_AIR_MEAN':'t2m'}) #rename to same names as ERA5 for coloc function\n",
    "ds=ds.rename({'RH_MEAN':'rh'})\n",
    "\n",
    "ERA5=xr.open_dataset('MasterH23/ERA5.nc')\n",
    "\n",
    "ERA5['P_SEA']=xr.open_dataset('MasterH23/ERA5p.nc').msl\n",
    "ERA5['v10']=xr.open_dataset('MasterH23/ERA5v10.nc').v10\n",
    "ERA5['sst']=xr.open_dataset('MasterH23/ERA5sst.nc').sst-273.15\n",
    "\n",
    "ERA5['d2m']=xr.open_dataset('MasterH23/ERA5d2m.nc').d2m\n",
    "ERA5['t2m']=xr.open_dataset('MasterH23/ERA5t2m.nc').t2m-273.15\n",
    "ERA5['dwlw']=xr.open_dataset('MasterH23/ERA5lwsw.nc').msdwlwrf\n",
    "ERA5['dwsw']=xr.open_dataset('MasterH23/ERA5lwsw.nc').msdwswrf\n",
    "ERA5['dwlwc']=xr.open_dataset('MasterH23/ERA5lwsw.nc').msdwlwrfcs\n",
    "ERA5['dwswc']=xr.open_dataset('MasterH23/ERA5lwsw.nc').msdwswrfcs\n",
    "ERA5['WIND_CORR10']=(ERA5.u10**2+ERA5.v10**2)**0.5\n",
    "ERA5['P_SEA']=ERA5['P_SEA']/100\n",
    "ERA5=era5dewtorh(ERA5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141760b4-efbc-416e-ab2b-98795dec2272",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save datasets as files\n",
    "ds.to_netcdf('MasterH23/ds.nc')\n",
    "ERA5.to_netcdf('MasterH23/ERA5file.nc') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b43599-f9b0-46ab-9126-08970d1ae33c",
   "metadata": {},
   "source": [
    "Create dsadcpH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22751316-8898-4950-a336-8212527dc394",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1638/1638 [00:15<00:00, 108.67it/s]\n"
     ]
    }
   ],
   "source": [
    "ds=xr.open_dataset('MasterH23/ds.nc')\n",
    "ERA5=xr.open_dataset('MasterH23/ERA5file.nc')\n",
    "\n",
    "dsH=ds.reset_coords().resample(time='1H').mean().set_coords(['latitude','longitude']) #resampla datasetet till 1H res.\n",
    "dsD=ds.reset_coords().resample(time='1D').mean().set_coords(['latitude','longitude']) #resample to daily res. for mapping\n",
    "\n",
    "adcp=xr.concat(files2,dim='time')\n",
    "gebco=xr.open_dataset('gebcoCT.nc') #ladda bathymetry\n",
    "adcpsur=adcp.sel(cell_depth=4.2) #Surface current-data\n",
    "\n",
    "\n",
    "adcpsur=adcpsur.rename({'vel_east':'u10'})\n",
    "adcpsur=adcpsur.rename({'vel_north':'v10'})\n",
    "\n",
    "adcpsurH=adcpsur.sortby('time').reset_coords().resample(time='1H').mean().set_coords(['latitude','longitude'])\n",
    "dsadcpH=dsH.sel(time=adcpsurH.time, method='nearest')\n",
    "\n",
    "dsadcpH['cur_u']=(adcpsurH.u10.values)\n",
    "dsadcpH['cur_v']=(adcpsurH.v10.values)\n",
    "\n",
    "dsadcpH['cur_u']=dsadcpH['cur_u'].swap_dims({\"cur_u\": \"time\"})\n",
    "dsadcpH['cur_v']=dsadcpH['cur_v'].swap_dims({\"cur_v\": \"time\"})\n",
    "dsadcpH['dist']=dist_era5_sd(dsadcpH ,ERA5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd854e-ce3e-4363-8822-fd654a4d30bb",
   "metadata": {},
   "source": [
    "Save dsadcpH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae474cf-d5aa-40ab-aa75-16283e971c13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dsadcpH.to_netcdf('MasterH23/dsadcpH.nc') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ca1d7-9048-4ffc-b1ea-a0743ee523db",
   "metadata": {},
   "source": [
    "Ostia cut off the right area and regrid to hourly times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c179465-2650-4055-abb5-74271199a0b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ostia= xr.concat(files3,dim='time') \n",
    "ostia=ostia.rename({'lon':'longitude'})\n",
    "ostia=ostia.rename({'lat':'latitude'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "445e465c-8b78-4d36-90e4-7f9e29e661f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date= dsadcpH.time.min()\n",
    "end_date=dsadcpH.time.max()\n",
    "lon_max= dsadcpH.longitude.max()\n",
    "lon_min= dsadcpH.longitude.min()\n",
    "\n",
    "lat_max=dsadcpH.latitude.max()\n",
    "lat_min=dsadcpH.latitude.min()\n",
    "\n",
    "\n",
    "cond1= (ostia.latitude>=lat_min) & (ostia.latitude<=lat_max) & (ostia.longitude>=lon_min) & (ostia.longitude<=lon_max) \n",
    "ostia=ostia.where(cond1 ,drop=True) \n",
    "ostia=ostia.reset_coords().resample(time='1H').pad()\n",
    "mask = (ostia['time'] >= start_date) & (ostia['time'] <= end_date)# & (ostia['longitude'] >= lon_min) & (ostia['longitude']<= lon_max) & (ostia['latitude'] >= lat_min) & (ostia['latitude']<= lat_max)\n",
    "ostia=ostia.sel(time=mask)\n",
    "ostia=ostia.rename({'analysed_sst':'sst'})\n",
    "#reset_coords().resample(time='1H').mean().set_coords(['latitude','longitude'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee0c88-15ce-454f-999a-7d892753d658",
   "metadata": {},
   "source": [
    "Save ostia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6765be17-8a34-4651-996e-dca74a5dd940",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save datasets as files\n",
    "ostia.to_netcdf('MasterH23/ostia.nc') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021d7a1-e0b0-46b8-9e88-b43fcd3308a2",
   "metadata": {},
   "source": [
    "CREATE & SAVE COLOC3 IF MODIFIED\n",
    "MAIN COLOC DATASET: Create coloc3, colocated adcpds dataset to ERA5 non masked\n",
    "\n",
    "Create relative u and v-speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3884f571-b276-4f50-8edf-1bd2d793486c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 190.66it/s]\n",
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 197.62it/s]\n",
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 204.35it/s]\n",
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 204.73it/s]\n",
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 204.73it/s]\n",
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 204.23it/s]\n",
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 198.61it/s]\n",
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 201.41it/s]\n",
      "100%|██████████████████████████████████████| 1638/1638 [00:08<00:00, 198.51it/s]\n"
     ]
    }
   ],
   "source": [
    "variables=['P_SEA', 'WIND_CORR10', 'u10', 'v10','dwlw', 'dwsw', 'sst', 't2m', 'rh' ]\n",
    "coloc3=pd.DataFrame(columns=variables)\n",
    "#msk=np.isfinite(dsadcpH.P_SEA)\n",
    "\n",
    "for i in np.arange(len(variables)):\n",
    "    #coloc3[variables[i]]=colocate_era5_sd(dsadcpH.sel(time=msk), ERA5, variables[i])\n",
    "    coloc3[variables[i]]=colocate_era5_sd(dsadcpH, ERA5, variables[i])\n",
    "    \n",
    "    \n",
    "coloc3['rel_u']= -coloc3['u10']+dsadcpH['cur_u']\n",
    "coloc3['rel_v']= -coloc3['v10']+dsadcpH['cur_v'] #Think about this!!! different conventions for wind and currentdirections\n",
    "\n",
    "coloc3['abs_rel']=(coloc3['rel_u']**2+coloc3['rel_v']**2)**0.5\n",
    "\n",
    "coloc3.to_csv('MasterH23/coloc3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb510b-ab62-4246-a296-d433c9779b2c",
   "metadata": {},
   "source": [
    "## Crucial dataset making code up until here, below only code to use for masked datasets to be copy and pasted into notebooks for stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013082d7-e862-475d-b856-8fce30e12b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset('MasterH23/ds.nc')\n",
    "ERA5=xr.open_dataset('MasterH23/ERA5file.nc')\n",
    "coloc3=pd.read_csv('MasterH23/coloc3.csv') #open coloc3\n",
    "dsadcpH=xr.open_dataset('MasterH23/dsadcpH.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd56b5-1b87-42fb-ac4e-1ae3db435d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53041b87-46fc-4e8e-a2b2-4959d9c4726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colocOSTIA=colocate_era5_sd(dsadcpH, ostia, 'sst')-273.15\n",
    "#colocOSTIAmsk=colocate_era5_sd(dsadcpH.sel(time=np.isfinite(dsadcpH.sst)), ostia, 'sst')-273.15\n",
    "distOSTIA=dist_era5_sd(dsadcpH, ostia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a392423-469d-48f0-b81c-6550b27b1b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d335581-1f01-4ed3-8fc2-1c060c964311",
   "metadata": {},
   "source": [
    "COLOC3MSK, necessary for hist2d plots and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916dd836-7ffc-449a-8c20-dd2038e9bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=['P_SEA', 'WIND_CORR10', 'u10', 'v10','dwlw', 'dwsw', 'sst', 't2m' , 'rh']\n",
    "coloc3msk=[] \n",
    "for i in np.arange(len(variables)):\n",
    "    msk=np.isfinite(dsadcpH[variables[i]])\n",
    "    coloc3msk.append(colocate_era5_sd(dsadcpH.sel(time=msk), ERA5, variables[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6e1b7-e164-44cf-a1a5-b27cb0d5714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is now on GitHub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
